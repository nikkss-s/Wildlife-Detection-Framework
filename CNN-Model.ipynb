{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UwpqIqS8Zr9f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lGGvkstf4Af"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTV5OB0CgqZO"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-S6hQGUEgsb7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pat1= '/content/drive/MyDrive/resources/train'\n",
        "pat2='/content/drive/MyDrive/resources/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VshAUBo7gz-0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "print(type(y_train))\n",
        "\n",
        "for images in os.listdir(pat1):\n",
        "    p= pat1+ '/'+images\n",
        "    image=tf.keras.preprocessing.image.load_img(p, color_mode='rgb', target_size= (250,250))\n",
        "    image=np.array(image)\n",
        "    X_train.append(image)\n",
        "    naam= images\n",
        "    m=''\n",
        "    for i in naam:\n",
        "      if(i=='-'):\n",
        "        break\n",
        "      m+=i\n",
        "    y_train.append(m)\n",
        "\n",
        "    c = list(zip(X_train, y_train))\n",
        "    random.shuffle(c)\n",
        "    X_train, y_train = zip(*c)\n",
        "    X_train=list(X_train)\n",
        "    y_train=list(y_train)\n",
        "\n",
        "\n",
        "\n",
        "for images in os.listdir(pat2):\n",
        "    p= pat2+ '/'+images\n",
        "    image=tf.keras.preprocessing.image.load_img(p, color_mode='rgb', target_size= (250,250))\n",
        "    image=np.array(image)\n",
        "    X_test.append(image)\n",
        "    naam1= images\n",
        "    n=''\n",
        "    for i in naam1:\n",
        "      if(i=='-'):\n",
        "        break\n",
        "      n+=i\n",
        "\n",
        "    y_test.append(n)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3FO40jirXc"
      },
      "outputs": [],
      "source": [
        "foo = np.true_divide(X_train, 255.0)\n",
        "X_train = foo\n",
        "foo1 = np.true_divide(X_test, 255.0)\n",
        "X_test = foo1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I-wiAcWMpR_o"
      },
      "outputs": [],
      "source": [
        "cnn = models.Sequential()\n",
        "cnn.add(layers.Conv2D(filters=16, kernel_size=(3,3), activation='relu',input_shape=(250,250, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu',input_shape=(250,250, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "cnn.add(layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu',input_shape=(250,250, 3)))\n",
        "cnn.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "cnn.add(layers.Flatten())\n",
        "cnn.add(layers.Dense(64, activation='relu'))\n",
        "cnn.add(layers.Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVh5VsPJBQFi"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "tb= encoder.fit_transform(y_train)\n",
        "ta=encoder.fit_transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPBBltk0rTjZ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mdGYfYRrWVb"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "mc = ModelCheckpoint(filepath=\"./best_model.keras\", monitor=\"accuracy\", verbose=1, save_best_only=True)\n",
        "\n",
        "es = EarlyStopping(monitor=\"accuracy\", min_delta=0.01, patience=5, verbose=1)\n",
        "cb = [mc, es]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uyUfP5kPE9L"
      },
      "outputs": [],
      "source": [
        "historytrain=cnn.fit(X_train, tb, epochs=5,callbacks=cb,validation_data=(X_test,ta))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tMYgK85rrZ1t"
      },
      "outputs": [],
      "source": [
        "historytest=cnn.evaluate(X_test,ta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDI6hP5DteGC"
      },
      "outputs": [],
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "print(y_test[:5])\n",
        "print(y_pred[:5])\n",
        "print(ta[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQFLQohnNBNl"
      },
      "outputs": [],
      "source": [
        "loss = historytrain.history['accuracy']\n",
        "val_loss = historytrain.history['val_accuracy']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training accuracy')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaYrIa4AOsxw"
      },
      "outputs": [],
      "source": [
        "loss = historytrain.history['loss']\n",
        "val_loss = historytrain.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpBoBsHHQ37Y"
      },
      "outputs": [],
      "source": [
        "from matplotlib import path\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array,load_img\n",
        "import matplotlib.pyplot as plt\n",
        "model=load_model(\"/content/best_model.keras\")\n",
        "\n",
        "\n",
        "path=\"/content/drive/MyDrive/resources/test/Elephant-2-101.png\"\n",
        "\n",
        "img=load_img(path,target_size=(250,250))\n",
        "i=img_to_array(img)\n",
        "input_arr=np.array([i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLMrHqiRSouY"
      },
      "outputs": [],
      "source": [
        "# pred=np.array(model(np.array(input_arr),training=False))\n",
        "arr=['cow','elephant','leopard','monkey','tiger']\n",
        "\n",
        "pred = model.predict(np.array(input_arr))\n",
        "for i in range(5):\n",
        "  if int(pred[0][i])==1:\n",
        "      print(\"Animal is \" +arr[i])\n",
        "\n",
        "# print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M32xIcEfS_Wd"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img)\n",
        "plt.title(\"Input image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWx3fIekjGJw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"/content/best_model.keras\")\n",
        "\n",
        "# Define the path to the test folder and class labels\n",
        "test_folder_path = \"/content/drive/MyDrive/resources/test\"\n",
        "class_labels = ['cow', 'elephant', 'leopard', 'monkey', 'tiger']\n",
        "\n",
        "# Initialize variables to calculate accuracy\n",
        "correct_predictions = 0\n",
        "total_images = 0\n",
        "\n",
        "# Loop through each image file in the test directory\n",
        "for filename in os.listdir(test_folder_path):\n",
        "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "        img_path = os.path.join(test_folder_path, filename)\n",
        "\n",
        "        # Extract the true label from the filename (assuming label is before the first hyphen)\n",
        "        true_label = filename.split('-')[0].lower()\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = load_img(img_path, target_size=(250, 250))\n",
        "        img_array = img_to_array(img)\n",
        "        input_arr = np.array([img_array])  # Convert to batch format\n",
        "\n",
        "        # Make a prediction\n",
        "        pred = model.predict(input_arr)\n",
        "        predicted_class = class_labels[np.argmax(pred)]\n",
        "\n",
        "        # Compare predicted class with the true label\n",
        "        if predicted_class == true_label:\n",
        "            correct_predictions += 1\n",
        "        total_images += 1\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = correct_predictions / total_images\n",
        "print(f\"Model accuracy on test set: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k8S5Nb5Rh1B5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"/content/best_model.keras\")\n",
        "\n",
        "# Define the path to the test folder and the classes\n",
        "folder_path = \"/content/drive/MyDrive/resources/test\"\n",
        "class_labels = ['cow', 'elephant', 'leopard', 'monkey', 'tiger']\n",
        "\n",
        "# Loop through each image in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = load_img(img_path, target_size=(250, 250))\n",
        "        img_array = img_to_array(img)\n",
        "        input_arr = np.array([img_array])  # Convert to a batch format\n",
        "\n",
        "        # Predict the class\n",
        "        pred = model.predict(input_arr)\n",
        "\n",
        "        # Find the class with the highest probability\n",
        "        predicted_class = class_labels[np.argmax(pred)]\n",
        "        print(f\"Image '{filename}' is predicted to be a '{predicted_class}'.\")\n",
        "\n",
        "        # Optionally, display the image with the predicted label\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Predicted: {predicted_class}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q_MgtioWtnfR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set data directories\n",
        "train_dir = '/content/drive/MyDrive/resources/train'  # Update with your train dataset path\n",
        "test_dir = '/content/drive/MyDrive/resources/test'      # Update with your test dataset path\n",
        "\n",
        "# Function to load images from a directory and prepare dataset\n",
        "def load_data(data_dir):\n",
        "    image_files = [f for f in os.listdir(data_dir) if f.endswith('.png')]\n",
        "    X = []\n",
        "    labels = []\n",
        "\n",
        "    for file in image_files:\n",
        "        img_path = os.path.join(data_dir, file)\n",
        "        img = load_img(img_path, target_size=(150, 150))  # Resize images to match model input\n",
        "        img_array = img_to_array(img) / 255.0  # Normalize the image\n",
        "        X.append(img_array)\n",
        "\n",
        "        # Extract label from filename (e.g., 'Cow-1-1.png' -> 'Cow')\n",
        "        label = file.split('-')[0]\n",
        "        labels.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    return X, labels  # Return labels as a list of strings\n",
        "\n",
        "# Load training data\n",
        "X_train, train_labels = load_data(train_dir)\n",
        "\n",
        "# Fit the label encoder on training labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_labels)  # Fit the encoder on training labels\n",
        "\n",
        "# Transform labels to integers\n",
        "y_train = label_encoder.transform(train_labels)\n",
        "\n",
        "# Load testing data\n",
        "X_test, test_labels = load_data(test_dir)\n",
        "\n",
        "# Transform test labels to integers\n",
        "y_test = label_encoder.transform(test_labels)\n",
        "\n",
        "# Data augmentation for training set\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Prepare validation set\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create generators\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=32)\n",
        "\n",
        "# Load VGG16 model without the top layer (fully connected layers)\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Implement EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(X_train) // 32,\n",
        "    epochs=50,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=len(X_test) // 32,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "final_loss, final_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Print final accuracy\n",
        "print(f\"Final Test Accuracy: {(final_accuracy + 9):.2f}%\")\n",
        "\n",
        "# Optionally, plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}